# Environment configuration for Cahoots Monolith

# Redis Configuration
REDIS_HOST=localhost
REDIS_PORT=6379
REDIS_DB=0
REDIS_PASSWORD=

# LLM Configuration
# Provider: mock, openai, groq, lambda, cerebras, local
LLM_PROVIDER=cerebras

# OpenAI Configuration
OPENAI_API_KEY=
OPENAI_MODEL=gpt-4

# Groq Configuration
GROQ_API_KEY=
GROQ_MODEL=mixtral-8x7b-32768

# Lambda Labs Configuration
LAMBDA_API_KEY=
LAMBDA_MODEL=hermes-3-llama-3.1-405b-fp8

# Cerebras Configuration
CEREBRAS_API_KEY=
CEREBRAS_MODEL=qwen-3-235b-a22b-instruct-2507

# Local LLM Configuration (vLLM)
# Note: Due to Docker Desktop GPU limitations, run vLLM directly on host:
#   1. Run: ./scripts/start_vllm.sh (in a separate terminal)
#   2. Set LLM_PROVIDER=local below
#   3. The script will start vLLM on port 8001
LOCAL_LLM_URL=http://localhost:8001/v1
LOCAL_LLM_MODEL=Qwen/Qwen2.5-Coder-32B-Instruct

# Application Configuration
HOST=0.0.0.0
PORT=8000
ENV=development

# Task Processing Configuration
MAX_DEPTH=5
MAX_SUBTASKS=7
COMPLEXITY_THRESHOLD=0.45
CACHE_TTL=3600
USE_SEMANTIC_CACHE=true
BATCH_SIZE=5

GOOGLE_CLIENT_ID=your-google-client-id
GOOGLE_CLIENT_SECRET=your-google-client-secret

HUGGINGFACE_API_KEY=

# Contex (Context Engine) Configuration
# For local development (docker-compose): http://context-engine:8001
# For Railway/production: https://your-contex-instance.railway.app
CONTEXT_ENGINE_URL=http://context-engine:8001
# API key is generated on first start - check docker compose logs context-engine
CONTEXT_ENGINE_API_KEY=

# Email Configuration (for blog notifications)
# Provider: resend (more coming soon)
EMAIL_PROVIDER=resend
# Get your API key from https://resend.com
EMAIL_API_KEY=
EMAIL_FROM=Cahoots <noreply@cahoots.cc>
FRONTEND_URL=https://cahoots.cc